---
title: "Monitor model for traffic crashes"
output: 
  vetiver::vetiver_dashboard:
    pins:
      board: !expr pins::board_rsconnect()
      name: 'julia.silge/traffic-crash-model'
      version: NULL
    storyboard: true
    source_code: https://github.com/juliasilge/modelops-playground
    theme: 
      version: 4
      bootswatch: cosmo
    display_pins: true
---

```{r setup, include = FALSE}
library(flexdashboard)
library(dplyr)
library(ggplot2)
library(lubridate)
library(RSocrata)
library(vetiver)
library(pins)
library(plotly)
library(leaflet)
library(reactable)
library(baguette)
library(parsnip)
library(recipes)
library(rpart)
library(themis)
library(workflows)
library(yardstick)

knitr::opts_chunk$set(echo = FALSE)
pins <- get_vetiver_dashboard_pins()
metrics_pin_name <- paste(pins$name, "metrics", sep = "-")
```

```{r load-vetiver-model, include = FALSE}
# Load deployed model from pin:
v <- vetiver_pin_read(pins$board, pins$name, version = pins$version)
meta <- pin_meta(pins$board, pins$name, version = pins$version)
days_old <- difftime(Sys.Date(), as.Date(meta$created), units = "days")
```

```{r validation, include = FALSE}
# Load new validation data, from API:

weeks_ago <- today() - weeks(2)
crash_url <- glue::glue("https://data.cityofchicago.org/Transportation/Traffic-Crashes-Crashes/85ca-t3if?$where=CRASH_DATE > '{weeks_ago}'")
crash_raw <- as_tibble(read.socrata(crash_url))
validation_df <- crash_raw %>%
  arrange(desc(crash_date)) %>%
  transmute(injuries = if_else(injuries_total > 0, "injuries", "none"),
            injuries = factor(injuries),
            crash_date = as.Date(crash_date),
            crash_hour,
            report_type = if_else(report_type == "", "UNKNOWN", report_type),
            num_units,
            posted_speed_limit,
            weather_condition,
            lighting_condition,
            roadway_surface_cond,
            first_crash_type,
            trafficway_type,
            prim_contributory_cause,
            latitude, longitude) %>%
  na.omit() %>%
  arrange(crash_date)

validation_aug <- augment(v, validation_df)

new_metrics <-
  validation_aug %>%
  vetiver_compute_metrics(crash_date, "week", injuries, 
                          .pred_class, .pred_injuries)

updated_metrics <- 
  vetiver_pin_metrics(
    pins$board, 
    new_metrics, 
    metrics_pin_name, 
    overwrite = TRUE
  )
```


### Model metrics

```{r}
## get training metrics expected from model
model_metrics <- tibble::as_tibble(v$metadata$user$metrics)

p1 <- updated_metrics %>%
  ## you can operate on your metrics as needed:
  filter(.metric %in% c("accuracy", "roc_auc"), .n > 20) %>%
  vetiver_plot_metrics() + 
  ## you can also operate on the ggplot:
  geom_hline(aes(yintercept = .estimate, color = .metric), 
             data = model_metrics,
             alpha = 0.7, size = 1.2, lty = 2) +
  scale_size(range = c(0, 5)) +
  theme_light()

p1 <- ggplotly(p1)
hide_legend(p1)
```

***

This dashboard monitors a model for [traffic crashes in Chicago](https://data.cityofchicago.org/Transportation/Traffic-Crashes-Crashes/85ca-t3if) that predicts whether a crash involves an injury or not. Learn more about this model monitoring project here:

<https://github.com/juliasilge/modelops-playground>

The dashed lines correspond to the model metrics (accuracy and ROC AUC) measured on **testing** data when the model was last trained, `r as.numeric(days_old)` days ago.


### Explore validation data

```{r}
p2 <- validation_df %>%
  count(injuries) %>% 
  ggplot(aes(injuries, n)) + 
  geom_col() + 
  labs(x = NULL, y = "Number of crashes") +
  theme_minimal()

ggplotly(p2)
```


***

This plot shows the _new_ crashes used for monitoring since the last time this dashboard was generated.

This data exhibits class imbalance, which was addressed during modeling via downsampling.

### Which crashes were misclassified by the bagged tree model?

```{r}
validation_aug %>%
  select(-crash_date, -latitude, -longitude) %>%
  filter((.pred_injuries > 0.8 & injuries == "none") | (.pred_injuries < 0.2 & injuries == "injuries")) %>%
  arrange(.pred_injuries) %>%
  select(`probability of injury` = .pred_injuries, everything()) %>%
  reactable(defaultSorted = c("probability of injury"), filterable = TRUE,
            defaultColDef = colDef(header = function(value) gsub("_", " ", value, fixed = TRUE)),
            columns = list(injuries = colDef(name = "any injuries?"))
  )
```

*** 

This table shows the _new_ crashes that our model did the worst job at classifying, in either direction.

Sort and filter to explore these misclassifications.


### How are the crashes distributed across Chicago?

```{r}
pal <- colorFactor(c("gray20", "palevioletred3"), domain = c("injuries", "none"))

validation_df %>%
  filter(latitude > 0) %>% 
  leaflet() %>% 
  addTiles() %>% 
  addCircleMarkers(color = ~pal(injuries)) %>%
  addLegend(title = "Crash type", pal = pal, values = ~injuries, opacity = 1)
```

***

[This dataset](https://data.cityofchicago.org/Transportation/Traffic-Crashes-Crashes/85ca-t3if) covers traffic crashes on city streets within Chicago city limits under the jurisdiction of the Chicago Police Department. 

This map, like the previous panels, shows the _new_ crashes used for monitoring since the last time this dashboard was generated.


### API visual documentation

```{r echo=FALSE, out.width="100%"}
## use your own vetiver model API URL here:
knitr::include_url("https://colorado.rstudio.com/rsc/traffic-crashes/", height = "600px")
```

***

Interact directly with the model for crashes via its visual documentation, and get `curl` examples.

